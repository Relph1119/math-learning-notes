# 第6部分 概率和数理统计篇

## 第12章 随机性和概率论：如何看待不确定性

- 拉普拉斯的古典概率：$\displaystyle P(A) = \frac{\text{随机事件A中所包含的单位事件的数量}}{\text{随机变量空间里的单位事件的数量}}$
- 伯努利试验：对于一般的情况，如果每一次伯努利试验时事件A发生的概率为$p$，进行$N$次试验后，恰好发生了$k$次，这个概率为
$$
P(N,k,p) = 
\left ( \begin{array}{} N \\ k \end{array} \right ) p ^k \cdot (1 - p)^{N - k}
$$
其中$\left ( \begin{array}{} N \\ k \end{array} \right )$是从$N$个物品中挑选出$k$个的组合数，它等于$\displaystyle \frac{N!}{k!(N-k)!}$
- 数学期望值只能反映一个随机变量平均的情况，不能反映它的浮动范围，页不饿能反映进行一次随机试验，结果是否在平均值的附近。
- 一个随机变量的概率分布曲线越平，方差越大，越向中间集中，方差越小。

## 第13章 小概率和大概率：如何资源共享和消除不确定性

- 泊松分布：如果随机事件A发生的概率是$p$，进行$n$次独立的试验，恰巧发生了$k$次，则相应的概率为
$$
p(X=k) = e^{-\lambda} \cdot \frac{\lambda^k}{k!}
$$
其中，$\lambda = n \cdot p$
- $3 \sigma$原则：也被称为68-95-99.7原则，它们是在1、2和3个$\sigma$的动态范围内相应的置信度。
- 早期概率论的缺失：没有证明古典概率的定义和基于统计的概率的定义在数学上是一回事；不能笼统地讲，只要试验次数足够多，误差就非常小。
- 公理化概率论的建立：
    - 样本空间$\Omega$：包含随机事件所有可能的结果。
    - 随机事件空间$F$：包含所有的随机事件。
    - 函数（也称为测度）$P$：将集合中的任何一个随机事件对应一个数值$P: F \to R$
    - 公理一：任何事件的概率是在0和1之间的一个实数。
    - 公理二：样本空间的概率为1，即$P(\Omega) = 1$。
    - 公理三：如果两个随机事件A和B是互斥的，那么，A发生或B发生这件事发生的概率，也就是A单独发生的概率，加上B单独发生的概率。即：如果$A \cap B = \emptyset，那么P(A \cup B) = P(A) + P(B)$

## 第14章 前提条件：度量随机性的新方法

- 条件概率公式：$\displaystyle P(A|B) = \frac{P(A,B)}{P(B)}$
- 概率和条件概率使用的三个误区：
    - 有意无意地漏掉了部分选项。
    - 在穷举了过去的、我们已经看到的全部情况后，就以为它涵盖了未来的各种可能情况。
    - 很多人总是不自觉地选择对自己有利的条件做判断，以至于过高地估计成功率，过低地估计失败率。
- 贝叶斯公式：$\displaystyle P(X|Y) = \frac{P(Y|X) \cdot P(X)}{P(Y)}$

## 第15章 统计学和数据方法：准确估算概率的前提

- 描述统计学，研究如何让统计的结果更有说服力。
- 统计工作的误区：
    - 非常牵强地寻找不是规律的规律。
    - 忽略了做统计的主观行为对统计结果的影响。
- 霍桑效应：当被观察者知道自己成为被观察对象而改变行为倾向的反应。
- 怎样做好统计：
    1. 设立研究目标
    2. 设计试验，选取数据
    3. 根据实验方案进行统计和实验，分析方差
    4. 分析和解释统计结果，并且根据分析进一步了解数据，提出新假说。
    5. 使用研究结果。
- 使用了数据却失败的原因：没有找到具有代表性的样本；低估了数据的稀疏性所带来的副作用；*“原因的原因不是原因”*
- 齐普夫定律：一个词的排位和它词频的乘积，近乎一个常数。
- 古德思想的核心：从高频的随机事件中拿出一点概率总量分配到低频的随机事件上，再从低频的随机事件中拿出一些概率总量，分配给再统计时没有见到的随机事件。
